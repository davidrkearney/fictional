[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fictional",
    "section": "",
    "text": "news\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-06-19-health_data.html",
    "href": "posts/2021-06-19-health_data.html",
    "title": "Forecasting running data",
    "section": "",
    "text": "from datetime import date\nimport os \ntoday = date.today()\n\n\nfor file in os.listdir():\n    if file.endswith('.ipynb'):\n        cd=today\n        os.rename(file, f'{today}-{file}')\n\n\nimport shutil\n\nshutil.copy(\n    os.path.join('2021-06-19-health_data.ipynb'),\n    os.path.join('../git-repos/Kearney_Data_Science/_notebooks')\n)\n\n'../git-repos/Kearney_Data_Science/_notebooks/2021-06-19-health_data.ipynb'\n\n\n\nimport sqlalchemy as db\nfrom sqlalchemy import create_engine\nimport sqlite3\nimport pandas as pd\n\nengine = db.create_engine('sqlite:///../../Downloads/fitbit.db')\nconnection = engine.connect()\nmetadata = db.MetaData()\n\n\n\nsql = \"\"\"\nselect DATE(date_time) as day\n, sum(distance_miles) as distance\nfrom distance_v\ngroup by DATE(date_time)\n\"\"\"\n\ncnxn = connection\n\ndf = pd.read_sql(sql, cnxn)\n\ndf\n\n\n\n\n\n  \n    \n      \n      day\n      distance\n    \n  \n  \n    \n      0\n      2020-12-02\n      11.238989\n    \n    \n      1\n      2020-12-03\n      7.615898\n    \n    \n      2\n      2020-12-04\n      11.392033\n    \n    \n      3\n      2020-12-05\n      9.929077\n    \n    \n      4\n      2020-12-06\n      10.442889\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      186\n      2021-06-08\n      0.935723\n    \n    \n      187\n      2021-06-09\n      4.844334\n    \n    \n      188\n      2021-06-10\n      8.554417\n    \n    \n      189\n      2021-06-11\n      6.167171\n    \n    \n      190\n      2021-06-12\n      5.006263\n    \n  \n\n191 rows × 2 columns\n\n\n\n\ndf['ds'] = df.day\ndf['y'] = df.distance\n\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 191 entries, 0 to 190\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   day       191 non-null    object \n 1   distance  191 non-null    float64\n 2   ds        191 non-null    object \n 3   y         191 non-null    float64\ndtypes: float64(2), object(2)\nmemory usage: 6.1+ KB\n\n\n\nimport statsmodels.api as sm\nimport pandas as pd\nfrom prophet import Prophet\n\n\nimport pandas as pd\npd.set_option('compute.use_numexpr', False)\n\nm = Prophet()\nm.fit(df)\n\nINFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\nINFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n\n\n<prophet.forecaster.Prophet at 0x7f0100bb6c70>\n\n\n\nfuture = m.make_future_dataframe(periods=365)\nfuture.tail()\n\n\n\n\n\n  \n    \n      \n      ds\n    \n  \n  \n    \n      551\n      2022-06-08\n    \n    \n      552\n      2022-06-09\n    \n    \n      553\n      2022-06-10\n    \n    \n      554\n      2022-06-11\n    \n    \n      555\n      2022-06-12\n    \n  \n\n\n\n\n\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\n\n\n\n\n  \n    \n      \n      ds\n      yhat\n      yhat_lower\n      yhat_upper\n    \n  \n  \n    \n      551\n      2022-06-08\n      9.954126\n      5.626830\n      14.090458\n    \n    \n      552\n      2022-06-09\n      11.067850\n      6.415623\n      15.269029\n    \n    \n      553\n      2022-06-10\n      9.524963\n      5.164365\n      13.816646\n    \n    \n      554\n      2022-06-11\n      10.393233\n      5.943450\n      14.634128\n    \n    \n      555\n      2022-06-12\n      11.320983\n      6.836854\n      15.647303\n    \n  \n\n\n\n\n\nfig1 = m.plot(forecast)\n\n\n\n\n\nfig2 = m.plot_components(forecast)\n\n\n\n\n\n# Python\nfig1 = m.plot(forecast)\n\n\n\n\n\n# Python\nfig2 = m.plot_components(forecast)\n\n\n\n\n\n# Python\nfrom prophet.plot import plot_plotly, plot_components_plotly\n\nplot_plotly(m, forecast)\n\n\n                                                \n\n\n\n# Python\nplot_components_plotly(m, forecast)\n\n\n                                                \n\n\n\n# Model fit\nm = Prophet() #Instanticate from Prophet class. \nm.fit(df) # Fit the Prophet model.\n\n# Predict\nfuture = m.make_future_dataframe(periods=365) # Make future date data frame for the next 365 days (it gives daily because it follows the frequency in input dataframe by default).\nforecast = m.predict(future) # Predict future value.\n\n# Plot results\nfig1 = m.plot(forecast) # Plot the fit to past data and future forcast.\nfig2 = m.plot_components(forecast) # Plot breakdown of components.\nplt.show()\nforecast # Displaying various results in table format.\n\nINFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\nINFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      ds\n      trend\n      yhat_lower\n      yhat_upper\n      trend_lower\n      trend_upper\n      additive_terms\n      additive_terms_lower\n      additive_terms_upper\n      weekly\n      weekly_lower\n      weekly_upper\n      multiplicative_terms\n      multiplicative_terms_lower\n      multiplicative_terms_upper\n      yhat\n    \n  \n  \n    \n      0\n      2020-12-02\n      8.826908\n      4.690634\n      11.818085\n      8.826908\n      8.826908\n      -0.380921\n      -0.380921\n      -0.380921\n      -0.380921\n      -0.380921\n      -0.380921\n      0.0\n      0.0\n      0.0\n      8.445987\n    \n    \n      1\n      2020-12-03\n      8.805304\n      5.826039\n      12.902548\n      8.805304\n      8.805304\n      0.727109\n      0.727109\n      0.727109\n      0.727109\n      0.727109\n      0.727109\n      0.0\n      0.0\n      0.0\n      9.532413\n    \n    \n      2\n      2020-12-04\n      8.783700\n      4.373529\n      11.382860\n      8.783700\n      8.783700\n      -0.821473\n      -0.821473\n      -0.821473\n      -0.821473\n      -0.821473\n      -0.821473\n      0.0\n      0.0\n      0.0\n      7.962227\n    \n    \n      3\n      2020-12-05\n      8.762096\n      5.593958\n      12.411443\n      8.762096\n      8.762096\n      0.041102\n      0.041102\n      0.041102\n      0.041102\n      0.041102\n      0.041102\n      0.0\n      0.0\n      0.0\n      8.803198\n    \n    \n      4\n      2020-12-06\n      8.740492\n      6.342656\n      13.346898\n      8.740492\n      8.740492\n      0.963158\n      0.963158\n      0.963158\n      0.963158\n      0.963158\n      0.963158\n      0.0\n      0.0\n      0.0\n      9.703650\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      551\n      2022-06-08\n      10.335047\n      5.742947\n      14.393370\n      7.579529\n      13.222686\n      -0.380921\n      -0.380921\n      -0.380921\n      -0.380921\n      -0.380921\n      -0.380921\n      0.0\n      0.0\n      0.0\n      9.954126\n    \n    \n      552\n      2022-06-09\n      10.340742\n      6.769705\n      15.861835\n      7.575976\n      13.239863\n      0.727109\n      0.727109\n      0.727109\n      0.727109\n      0.727109\n      0.727109\n      0.0\n      0.0\n      0.0\n      11.067850\n    \n    \n      553\n      2022-06-10\n      10.346436\n      4.792225\n      14.159937\n      7.573519\n      13.261637\n      -0.821473\n      -0.821473\n      -0.821473\n      -0.821473\n      -0.821473\n      -0.821473\n      0.0\n      0.0\n      0.0\n      9.524963\n    \n    \n      554\n      2022-06-11\n      10.352131\n      5.946817\n      14.833565\n      7.570061\n      13.285497\n      0.041102\n      0.041102\n      0.041102\n      0.041102\n      0.041102\n      0.041102\n      0.0\n      0.0\n      0.0\n      10.393233\n    \n    \n      555\n      2022-06-12\n      10.357825\n      7.099368\n      15.701414\n      7.563656\n      13.302798\n      0.963158\n      0.963158\n      0.963158\n      0.963158\n      0.963158\n      0.963158\n      0.0\n      0.0\n      0.0\n      11.320983\n    \n  \n\n556 rows × 16 columns\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# Load test data: log-transformed daily page views for the Wikipedia page for Peyton Manning.\n\ndf['cap'] = 10 # Saturating maximum\ndf['floor'] = 7 # Saturating minimum\n\n# Model setup\nm = Prophet(growth='logistic')\nm.add_country_holidays(country_name='US') # Adding US holiday regressor\nm.fit(df) \n\n# Future data generation\nfuture = m.make_future_dataframe(periods=365*5)\nfuture['cap'] = 10 # Saturating maximum\nfuture['floor'] = 7 # Saturating minimum\n\n# Future forecast\nforecast = m.predict(future) \n\nINFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\nINFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n\n\n\n\n# Visualize\nfig1 = m.plot(forecast) # Plot the fit to past data and future forcast.\nfig2 = m.plot_components(forecast) # Plot breakdown of components.\nplt.show()\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndef is_nfl_season(ds):\n    date = pd.to_datetime(ds)\n    return (date.month > 8 or date.month < 2)\n\ndf['on_season'] = df['ds'].apply(is_nfl_season) #on_season dummy.\ndf['off_season'] = ~df['ds'].apply(is_nfl_season) #off_season dummy.\n\n# set user-defined seasonality and fit\nm = Prophet(weekly_seasonality=False)\nm.add_seasonality(name='weekly_on_season', period=7, fourier_order=3, condition_name='on_season')\nm.add_seasonality(name='weekly_off_season', period=7, fourier_order=3, condition_name='off_season')\nm.fit(df)\n\n# Make the same columns to future data.\nfuture = m.make_future_dataframe(periods=365*5) # Make future date data frame for the next 365 days (it gives daily because it follows the frequency in input dataframe by default).\nfuture['on_season'] = future['ds'].apply(is_nfl_season)\nfuture['off_season'] = ~future['ds'].apply(is_nfl_season)\n\n# Predict future value.\nforecast = m.predict(future)\n\nINFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\nINFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n\n\n\n# Plot results\nfig1 = m.plot(forecast) # Plot the fit to past data and future forcast.\nfig2 = m.plot_components(forecast) # Plot breakdown of components.\nplt.show()\n\n\n\n\n\n\n\n\n# After getting forecast dataframe using user-defined seasonality \"on-season\"/\"off-season\" above...\n\nfrom statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n\ndf['ds'] = pd.to_datetime(df['ds'],format='%Y-%m-%d')\ndf_res = df.merge(forecast,how=\"inner\",on=\"ds\")\ndf_res['residual'] = df_res['y'] - df_res['yhat']\nplot_acf(df_res['residual'])\nplot_pacf(df_res['residual'])\nplt.show()"
  },
  {
    "objectID": "posts/2021-06-10-regression-pycaret-2.html",
    "href": "posts/2021-06-10-regression-pycaret-2.html",
    "title": "Regression using Fiscal Data with PyCaret",
    "section": "",
    "text": "# %load solutions/regression_example.py\n\nimport pandas as pd\nurl = 'https://raw.githubusercontent.com/davidrkearney/Kearney_Data_Science/master/_notebooks/df_panel_fix.csv'\ndf = pd.read_csv(url, error_bad_lines=False)\ndf\n\nimport sklearn\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\n\n\n\ndf.columns\n\nsklearn.set_config(display='diagram')\n\ndf=df.dropna()\n\ndf.isnull().sum()\n\n\n\nX, y = df.drop(['specific', 'Unnamed: 0'], axis = 1), df['specific']\n\n\nX = X.select_dtypes(include='number')\nX\n\n\n_ = X.hist(figsize=(30, 15), layout=(5, 8))\n\ndf=df.drop(['Unnamed: 0'], axis = 1)\n\n\n\n\n\nfrom pycaret.regression import *\nreg1 = setup(df, target = 'specific', session_id=153, log_experiment=True, experiment_name='fiscal')\n\n\n                    Description        Value    \n                \n                        0\n                        session_id\n                        153\n            \n            \n                        1\n                        Target\n                        specific\n            \n            \n                        2\n                        Original Data\n                        (118, 12)\n            \n            \n                        3\n                        Missing Values\n                        False\n            \n            \n                        4\n                        Numeric Features\n                        8\n            \n            \n                        5\n                        Categorical Features\n                        3\n            \n            \n                        6\n                        Ordinal Features\n                        False\n            \n            \n                        7\n                        High Cardinality Features\n                        False\n            \n            \n                        8\n                        High Cardinality Method\n                        None\n            \n            \n                        9\n                        Transformed Train Set\n                        (82, 47)\n            \n            \n                        10\n                        Transformed Test Set\n                        (36, 47)\n            \n            \n                        11\n                        Shuffle Train-Test\n                        True\n            \n            \n                        12\n                        Stratify Train-Test\n                        False\n            \n            \n                        13\n                        Fold Generator\n                        KFold\n            \n            \n                        14\n                        Fold Number\n                        10\n            \n            \n                        15\n                        CPU Jobs\n                        -1\n            \n            \n                        16\n                        Use GPU\n                        False\n            \n            \n                        17\n                        Log Experiment\n                        True\n            \n            \n                        18\n                        Experiment Name\n                        fiscal\n            \n            \n                        19\n                        USI\n                        0884\n            \n            \n                        20\n                        Imputation Type\n                        simple\n            \n            \n                        21\n                        Iterative Imputation Iteration\n                        None\n            \n            \n                        22\n                        Numeric Imputer\n                        mean\n            \n            \n                        23\n                        Iterative Imputation Numeric Model\n                        None\n            \n            \n                        24\n                        Categorical Imputer\n                        constant\n            \n            \n                        25\n                        Iterative Imputation Categorical Model\n                        None\n            \n            \n                        26\n                        Unknown Categoricals Handling\n                        least_frequent\n            \n            \n                        27\n                        Normalize\n                        False\n            \n            \n                        28\n                        Normalize Method\n                        None\n            \n            \n                        29\n                        Transformation\n                        False\n            \n            \n                        30\n                        Transformation Method\n                        None\n            \n            \n                        31\n                        PCA\n                        False\n            \n            \n                        32\n                        PCA Method\n                        None\n            \n            \n                        33\n                        PCA Components\n                        None\n            \n            \n                        34\n                        Ignore Low Variance\n                        False\n            \n            \n                        35\n                        Combine Rare Levels\n                        False\n            \n            \n                        36\n                        Rare Level Threshold\n                        None\n            \n            \n                        37\n                        Numeric Binning\n                        False\n            \n            \n                        38\n                        Remove Outliers\n                        False\n            \n            \n                        39\n                        Outliers Threshold\n                        None\n            \n            \n                        40\n                        Remove Multicollinearity\n                        False\n            \n            \n                        41\n                        Multicollinearity Threshold\n                        None\n            \n            \n                        42\n                        Clustering\n                        False\n            \n            \n                        43\n                        Clustering Iteration\n                        None\n            \n            \n                        44\n                        Polynomial Features\n                        False\n            \n            \n                        45\n                        Polynomial Degree\n                        None\n            \n            \n                        46\n                        Trignometry Features\n                        False\n            \n            \n                        47\n                        Polynomial Threshold\n                        None\n            \n            \n                        48\n                        Group Features\n                        False\n            \n            \n                        49\n                        Feature Selection\n                        False\n            \n            \n                        50\n                        Feature Selection Method\n                        classic\n            \n            \n                        51\n                        Features Selection Threshold\n                        None\n            \n            \n                        52\n                        Feature Interaction\n                        False\n            \n            \n                        53\n                        Feature Ratio\n                        False\n            \n            \n                        54\n                        Interaction Threshold\n                        None\n            \n            \n                        55\n                        Transform Target\n                        False\n            \n            \n                        56\n                        Transform Target Method\n                        box-cox\n            \n    \n\n\n\nbest_model = compare_models(fold=5)\n\n\n                    Model        MAE        MSE        RMSE        R2        RMSLE        MAPE        TT (Sec)    \n                \n                        ridge\n                        Ridge Regression\n                        203104.6812\n                        70889717760.0000\n                        264074.3844\n                        0.8726\n                        0.5540\n                        0.3956\n                        0.0080\n            \n            \n                        en\n                        Elastic Net\n                        214984.3531\n                        85422610841.6000\n                        290426.9344\n                        0.8517\n                        0.4986\n                        0.4002\n                        0.0100\n            \n            \n                        br\n                        Bayesian Ridge\n                        220166.1782\n                        95589994393.9887\n                        304401.6991\n                        0.8301\n                        0.4481\n                        0.3928\n                        0.0120\n            \n            \n                        huber\n                        Huber Regressor\n                        220856.7956\n                        112309915361.3680\n                        329346.7142\n                        0.8236\n                        0.4063\n                        0.3861\n                        0.0240\n            \n            \n                        lr\n                        Linear Regression\n                        232120.2812\n                        103810244608.0000\n                        317848.8281\n                        0.8138\n                        0.5000\n                        0.4204\n                        0.4660\n            \n            \n                        et\n                        Extra Trees Regressor\n                        221900.6764\n                        127140774212.6801\n                        338961.7060\n                        0.7945\n                        0.3815\n                        0.3499\n                        0.0580\n            \n            \n                        rf\n                        Random Forest Regressor\n                        237185.4749\n                        140134962286.5481\n                        359066.7448\n                        0.7677\n                        0.3845\n                        0.3603\n                        0.0680\n            \n            \n                        gbr\n                        Gradient Boosting Regressor\n                        238720.3298\n                        145838870195.5470\n                        366741.3828\n                        0.7624\n                        0.3810\n                        0.3619\n                        0.0200\n            \n            \n                        knn\n                        K Neighbors Regressor\n                        285577.7062\n                        149621195571.2000\n                        378386.5938\n                        0.7535\n                        0.4782\n                        0.4564\n                        0.0080\n            \n            \n                        omp\n                        Orthogonal Matching Pursuit\n                        238278.1124\n                        126779634746.9780\n                        340431.6364\n                        0.7507\n                        0.6785\n                        0.4087\n                        0.0060\n            \n            \n                        ada\n                        AdaBoost Regressor\n                        286133.9032\n                        178448925624.8169\n                        409351.8897\n                        0.7261\n                        0.4671\n                        0.4826\n                        0.0380\n            \n            \n                        par\n                        Passive Aggressive Regressor\n                        333654.6862\n                        255709611689.0604\n                        478365.7421\n                        0.6396\n                        0.6616\n                        0.4911\n                        0.0080\n            \n            \n                        lightgbm\n                        Light Gradient Boosting Machine\n                        333751.2407\n                        246645596801.5230\n                        489542.3762\n                        0.6196\n                        0.4881\n                        0.4594\n                        0.0140\n            \n            \n                        dt\n                        Decision Tree Regressor\n                        331466.4338\n                        251572931731.8265\n                        484401.1935\n                        0.5996\n                        0.4895\n                        0.4942\n                        0.0080\n            \n            \n                        lasso\n                        Lasso Regression\n                        472806.4594\n                        1744652831948.8000\n                        924353.6562\n                        -2.9647\n                        0.9793\n                        0.7323\n                        0.3020\n            \n            \n                        llar\n                        Lasso Least Angle Regression\n                        557614.3428\n                        2757565135711.8994\n                        1218269.0934\n                        -4.1517\n                        0.9882\n                        0.9808\n                        0.0120\n            \n            \n                        lar\n                        Least Angle Regression\n                        523505032166121.1875\n                        8777827809541126967434359603200.0000\n                        1651376809056778.0000\n                        -21875898822041108480.0000\n                        12.5860\n                        2953087708.0914\n                        0.0120\n            \n    \n\n\n\ngbr = create_model('gbr')\n\n\n                    MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        259539.4234\n                        188010814764.0497\n                        433602.1388\n                        0.2035\n                        0.3725\n                        0.3658\n            \n            \n                        1\n                        344439.6555\n                        261157479760.8762\n                        511035.6932\n                        0.7712\n                        0.2734\n                        0.2021\n            \n            \n                        2\n                        269448.7502\n                        89799376760.5959\n                        299665.4414\n                        0.2559\n                        0.5134\n                        0.5621\n            \n            \n                        3\n                        156389.8428\n                        56101010341.3762\n                        236856.5185\n                        0.9215\n                        0.3037\n                        0.2752\n            \n            \n                        4\n                        197734.1876\n                        68770895511.2340\n                        262242.0552\n                        0.8442\n                        0.4341\n                        0.4405\n            \n            \n                        5\n                        316382.5762\n                        190021156955.1915\n                        435914.1624\n                        0.8431\n                        0.3250\n                        0.3036\n            \n            \n                        6\n                        132877.7936\n                        48011457619.3648\n                        219115.1698\n                        0.9377\n                        0.1445\n                        0.1184\n            \n            \n                        7\n                        63780.4855\n                        6638335948.5179\n                        81475.9839\n                        0.9926\n                        0.2004\n                        0.1484\n            \n            \n                        8\n                        84622.6556\n                        19489890756.1842\n                        139606.1988\n                        0.8903\n                        0.5672\n                        0.5448\n            \n            \n                        9\n                        312499.9655\n                        219320548133.8201\n                        468316.7178\n                        0.6284\n                        0.4557\n                        0.4542\n            \n            \n                        Mean\n                        213771.5336\n                        114732096655.1211\n                        308783.0080\n                        0.7288\n                        0.3590\n                        0.3415\n            \n            \n                        SD\n                        95820.4252\n                        86484686219.4249\n                        139230.5665\n                        0.2673\n                        0.1285\n                        0.1501\n            \n    \n\n\n\nimport numpy as np\ngbrs = [create_model('gbr', learning_rate=i) for i in np.arange(0.1,1,0.1)]\n\n\n                    MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        214161.7167\n                        66589303052.3318\n                        258049.0323\n                        0.7179\n                        0.5064\n                        0.3315\n            \n            \n                        1\n                        383023.4934\n                        211259341300.2875\n                        459629.5697\n                        0.8149\n                        0.3382\n                        0.2795\n            \n            \n                        2\n                        239279.0742\n                        87706228150.9347\n                        296152.3732\n                        0.2732\n                        0.5829\n                        0.5918\n            \n            \n                        3\n                        192434.2246\n                        95811714139.4744\n                        309534.6736\n                        0.8660\n                        0.4334\n                        0.4130\n            \n            \n                        4\n                        142428.6249\n                        51054538060.0787\n                        225952.5128\n                        0.8843\n                        0.2410\n                        0.1901\n            \n            \n                        5\n                        367843.9369\n                        206432485479.9056\n                        454348.4186\n                        0.8295\n                        0.5008\n                        0.4725\n            \n            \n                        6\n                        228995.4083\n                        126313136112.6237\n                        355405.5938\n                        0.8362\n                        0.2683\n                        0.2024\n            \n            \n                        7\n                        158840.0937\n                        40230541391.6350\n                        200575.5254\n                        0.9550\n                        0.4181\n                        0.2684\n            \n            \n                        8\n                        195178.1770\n                        46865758291.9661\n                        216485.0071\n                        0.7363\n                        0.5635\n                        0.6440\n            \n            \n                        9\n                        371923.4898\n                        271120545391.5568\n                        520692.3712\n                        0.5406\n                        0.5683\n                        0.5885\n            \n            \n                        Mean\n                        249410.8239\n                        120338359137.0794\n                        329682.5078\n                        0.7454\n                        0.4421\n                        0.3982\n            \n            \n                        SD\n                        86305.1580\n                        77214568547.1943\n                        107924.9888\n                        0.1907\n                        0.1184\n                        0.1603\n            \n    \n\n\n\nprint(len(gbrs))\n\n9\n\n\n\ntuned_gbr = tune_model(gbr, n_iter=50, optimize = 'RMSE')\n\n\n                    MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        154942.6734\n                        74997708663.9170\n                        273857.0953\n                        0.6823\n                        0.2835\n                        0.2430\n            \n            \n                        1\n                        356026.5185\n                        259197991105.0069\n                        509114.9095\n                        0.7729\n                        0.3057\n                        0.2048\n            \n            \n                        2\n                        196245.5979\n                        50062838730.3433\n                        223747.2653\n                        0.5852\n                        0.4460\n                        0.4092\n            \n            \n                        3\n                        130813.1472\n                        28724978265.9940\n                        169484.4484\n                        0.9598\n                        0.3879\n                        0.3551\n            \n            \n                        4\n                        150379.1478\n                        58016543407.9028\n                        240866.2355\n                        0.8686\n                        0.3318\n                        0.2935\n            \n            \n                        5\n                        360842.5596\n                        256418976969.6155\n                        506378.2943\n                        0.7883\n                        0.3802\n                        0.3776\n            \n            \n                        6\n                        101664.5162\n                        23660563887.4224\n                        153819.9073\n                        0.9693\n                        0.1738\n                        0.1305\n            \n            \n                        7\n                        121078.1094\n                        22126447635.5874\n                        148749.6139\n                        0.9753\n                        0.3012\n                        0.2768\n            \n            \n                        8\n                        204892.4698\n                        59961129586.8548\n                        244869.6175\n                        0.6626\n                        0.7065\n                        0.9038\n            \n            \n                        9\n                        247798.4343\n                        119125737964.7928\n                        345145.9662\n                        0.7982\n                        0.3572\n                        0.3649\n            \n            \n                        Mean\n                        202468.3174\n                        95229291621.7437\n                        281603.3353\n                        0.8062\n                        0.3674\n                        0.3559\n            \n            \n                        SD\n                        88121.5888\n                        85677172457.2040\n                        126209.5604\n                        0.1300\n                        0.1326\n                        0.2000\n            \n    \n\n\n\ntuned_gbr\n\nGradientBoostingRegressorGradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n                          init=None, learning_rate=0.05, loss='ls', max_depth=8,\n                          max_features='sqrt', max_leaf_nodes=None,\n                          min_impurity_decrease=0.001, min_impurity_split=None,\n                          min_samples_leaf=3, min_samples_split=10,\n                          min_weight_fraction_leaf=0.0, n_estimators=260,\n                          n_iter_no_change=None, presort='deprecated',\n                          random_state=153, subsample=1.0, tol=0.0001,\n                          validation_fraction=0.1, verbose=0, warm_start=False)\n\n\n\ndt = create_model('dt')\n\n\n                    MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        207956.4444\n                        64209396573.1111\n                        253395.7312\n                        0.7280\n                        0.2948\n                        0.3014\n            \n            \n                        1\n                        524236.3333\n                        569991781768.5555\n                        754978.0009\n                        0.5006\n                        0.4063\n                        0.3254\n            \n            \n                        2\n                        329215.7500\n                        190393519675.5000\n                        436341.0589\n                        -0.5777\n                        0.5801\n                        0.6555\n            \n            \n                        3\n                        191451.2500\n                        124860637323.7500\n                        353356.2470\n                        0.8254\n                        0.4116\n                        0.3334\n            \n            \n                        4\n                        213423.5000\n                        76306439743.2500\n                        276236.2028\n                        0.8271\n                        0.5254\n                        0.3705\n            \n            \n                        5\n                        370690.3750\n                        199965742624.8750\n                        447175.2929\n                        0.8349\n                        0.5442\n                        0.4049\n            \n            \n                        6\n                        246669.8750\n                        129638363043.8750\n                        360053.2781\n                        0.8319\n                        0.2617\n                        0.2171\n            \n            \n                        7\n                        178672.0000\n                        77945893211.5000\n                        279187.9174\n                        0.9128\n                        0.3495\n                        0.3173\n            \n            \n                        8\n                        166587.8750\n                        46127063745.6250\n                        214772.1205\n                        0.7404\n                        0.4736\n                        0.4654\n            \n            \n                        9\n                        295026.8750\n                        185238337215.6250\n                        430393.2356\n                        0.6861\n                        0.3864\n                        0.3666\n            \n            \n                        Mean\n                        272393.0278\n                        166467717492.5666\n                        380588.9085\n                        0.6310\n                        0.4234\n                        0.3757\n            \n            \n                        SD\n                        105664.3855\n                        144523328671.4254\n                        147036.7308\n                        0.4171\n                        0.1010\n                        0.1121\n            \n    \n\n\n\nbagged_dt = ensemble_model(dt, n_estimators=50)\n\n\n                    MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        196727.1578\n                        90285018684.0473\n                        300474.6556\n                        0.6175\n                        0.3087\n                        0.2890\n            \n            \n                        1\n                        400549.3422\n                        340151201313.8998\n                        583224.8291\n                        0.7020\n                        0.3095\n                        0.2039\n            \n            \n                        2\n                        225912.9050\n                        72423782552.9881\n                        269116.6709\n                        0.3999\n                        0.4933\n                        0.5057\n            \n            \n                        3\n                        118783.1250\n                        22526053317.3862\n                        150086.8193\n                        0.9685\n                        0.3121\n                        0.2808\n            \n            \n                        4\n                        202532.9275\n                        80967074782.4978\n                        284547.1398\n                        0.8166\n                        0.4177\n                        0.4139\n            \n            \n                        5\n                        341289.0375\n                        234909197221.4275\n                        484674.3208\n                        0.8060\n                        0.3879\n                        0.3623\n            \n            \n                        6\n                        141661.2425\n                        37608256142.0725\n                        193928.4820\n                        0.9512\n                        0.1464\n                        0.1355\n            \n            \n                        7\n                        126158.8400\n                        34803232314.1118\n                        186556.2444\n                        0.9611\n                        0.3018\n                        0.2442\n            \n            \n                        8\n                        183361.3550\n                        44385100050.7344\n                        210677.7161\n                        0.7502\n                        0.5438\n                        0.5929\n            \n            \n                        9\n                        260316.8175\n                        176470763137.0123\n                        420084.2334\n                        0.7010\n                        0.3999\n                        0.3821\n            \n            \n                        Mean\n                        219729.2750\n                        113452967951.6178\n                        308337.1111\n                        0.7674\n                        0.3621\n                        0.3410\n            \n            \n                        SD\n                        87376.1209\n                        99179989784.9265\n                        135577.2615\n                        0.1680\n                        0.1066\n                        0.1322\n            \n    \n\n\n\nboosted_dt = ensemble_model(dt, method = 'Boosting')\n\n\n                    MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        261162.8889\n                        114911582041.3333\n                        338986.1089\n                        0.5132\n                        0.3872\n                        0.3925\n            \n            \n                        1\n                        422328.3333\n                        333782428795.6667\n                        577739.0664\n                        0.7076\n                        0.3211\n                        0.2542\n            \n            \n                        2\n                        232284.1250\n                        77562868468.1250\n                        278501.1104\n                        0.3573\n                        0.5087\n                        0.5015\n            \n            \n                        3\n                        197047.1250\n                        112221331803.8750\n                        334994.5250\n                        0.8431\n                        0.3502\n                        0.3395\n            \n            \n                        4\n                        285119.7500\n                        161644974606.0000\n                        402050.9602\n                        0.6338\n                        0.5596\n                        0.5738\n            \n            \n                        5\n                        473330.2500\n                        599114250508.0000\n                        774024.7092\n                        0.5053\n                        0.5119\n                        0.5217\n            \n            \n                        6\n                        108483.0000\n                        20435489036.7500\n                        142952.7511\n                        0.9735\n                        0.2098\n                        0.1500\n            \n            \n                        7\n                        157960.0000\n                        69455073830.5000\n                        263543.3054\n                        0.9223\n                        0.2735\n                        0.2394\n            \n            \n                        8\n                        120478.7500\n                        23354347455.5000\n                        152821.2925\n                        0.8686\n                        0.5655\n                        0.5893\n            \n            \n                        9\n                        231595.7500\n                        117602419885.0000\n                        342932.0922\n                        0.8007\n                        0.4401\n                        0.4379\n            \n            \n                        Mean\n                        248978.9972\n                        163008476643.0750\n                        360854.5921\n                        0.7125\n                        0.4128\n                        0.4000\n            \n            \n                        SD\n                        113864.7400\n                        167985632403.4423\n                        181086.8299\n                        0.1940\n                        0.1176\n                        0.1435\n            \n    \n\n\n\nplot_model(dt)\n\n\n\n\n\nplot_model(dt, plot = 'error')\n\n\n\n\n\nplot_model(dt, plot = 'feature')\n\n\n\n\n\nevaluate_model(dt)\n\n\n\n\n\n  \n    \n      \n      Parameters\n    \n  \n  \n    \n      ccp_alpha\n      0.0\n    \n    \n      criterion\n      mse\n    \n    \n      max_depth\n      None\n    \n    \n      max_features\n      None\n    \n    \n      max_leaf_nodes\n      None\n    \n    \n      min_impurity_decrease\n      0.0\n    \n    \n      min_impurity_split\n      None\n    \n    \n      min_samples_leaf\n      1\n    \n    \n      min_samples_split\n      2\n    \n    \n      min_weight_fraction_leaf\n      0.0\n    \n    \n      presort\n      deprecated\n    \n    \n      random_state\n      153\n    \n    \n      splitter\n      best\n    \n  \n\n\n\n\n\ninterpret_model(dt)\n\n\n\n\n\ninterpret_model(dt, plot = 'correlation')\n\n\n\n\n\ninterpret_model(dt, plot = 'reason', observation = 12)\n\n\n\n\n\n\n\n\n  Visualization omitted, Javascript library not loaded!\n  Have you run `initjs()` in this notebook? If this notebook was from another\n  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n  this notebook on github the Javascript has been stripped for security. If you are using\n  JupyterLab this error is because a JupyterLab extension has not yet been written.\n\n \n\n\n\nbest = automl(optimize = 'MAE')\nbest\n\nGradientBoostingRegressorGradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n                          init=None, learning_rate=0.05, loss='ls', max_depth=8,\n                          max_features='sqrt', max_leaf_nodes=None,\n                          min_impurity_decrease=0.001, min_impurity_split=None,\n                          min_samples_leaf=3, min_samples_split=10,\n                          min_weight_fraction_leaf=0.0, n_estimators=260,\n                          n_iter_no_change=None, presort='deprecated',\n                          random_state=153, subsample=1.0, tol=0.0001,\n                          validation_fraction=0.1, verbose=0, warm_start=False)\n\n\n\npred_holdouts = predict_model(dt)\npred_holdouts.head()\n\n\n                    Model        MAE        MSE        RMSE        R2        RMSLE        MAPE    \n                \n                        0\n                        Decision Tree Regressor\n                        330931.5556\n                        395886787646.2778\n                        629195.3494\n                        0.3277\n                        0.4581\n                        0.4602\n            \n    \n\n\n\n\n\n\n  \n    \n      \n      general\n      gdp\n      fdi\n      rnr\n      rr\n      i\n      fr\n      it\n      province_Anhui\n      province_Beijing\n      ...\n      year_2006\n      year_2007\n      reg_East China\n      reg_North China\n      reg_Northeast China\n      reg_Northwest China\n      reg_South Central China\n      reg_Southwest China\n      specific\n      Label\n    \n  \n  \n    \n      0\n      123546.0\n      2011.189941\n      12812.0\n      0.0\n      0.0\n      0.000000\n      1514364.0\n      2254281.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      436189.0\n      472786.0\n    \n    \n      1\n      36670.0\n      2312.820068\n      11169.0\n      0.0\n      0.0\n      0.000000\n      1600475.0\n      3035767.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      615593.0\n      601485.0\n    \n    \n      2\n      241282.0\n      6867.700195\n      53903.0\n      0.0\n      0.0\n      0.516129\n      2823413.0\n      3586373.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      685732.0\n      681676.0\n    \n    \n      3\n      581800.0\n      25776.910156\n      1101159.0\n      0.0\n      0.0\n      0.000000\n      16753980.0\n      6357869.0\n      0.0\n      0.0\n      ...\n      0.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      2121243.0\n      3860764.0\n    \n    \n      4\n      36946.0\n      445.359985\n      1743.0\n      0.0\n      0.0\n      0.000000\n      233299.0\n      736165.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      133858.0\n      107687.0\n    \n  \n\n5 rows × 49 columns\n\n\n\n\nnew_data = df.copy()\nnew_data.drop(['specific'], axis=1, inplace=True)\npredict_new = predict_model(best, data=new_data)\npredict_new.head()\n\n\n\n\n\n  \n    \n      \n      province\n      general\n      year\n      gdp\n      fdi\n      rnr\n      rr\n      i\n      fr\n      reg\n      it\n      Label\n    \n  \n  \n    \n      4\n      Anhui\n      32100.0\n      2000\n      2902.09\n      31847\n      0.0\n      0.0\n      0.000000\n      1601508\n      East China\n      1499110\n      2.000834e+05\n    \n    \n      6\n      Anhui\n      66529.0\n      2002\n      3519.72\n      38375\n      0.0\n      0.0\n      0.000000\n      1677840\n      East China\n      2404936\n      4.365530e+05\n    \n    \n      7\n      Anhui\n      52108.0\n      2003\n      3923.11\n      36720\n      0.0\n      0.0\n      0.000000\n      1896479\n      East China\n      2815820\n      6.096731e+05\n    \n    \n      10\n      Anhui\n      279052.0\n      2006\n      6112.50\n      139354\n      0.0\n      0.0\n      0.324324\n      3434548\n      East China\n      5167300\n      1.455109e+06\n    \n    \n      11\n      Anhui\n      178705.0\n      2007\n      7360.92\n      299892\n      0.0\n      0.0\n      0.324324\n      4468640\n      East China\n      7040099\n      2.000116e+06\n    \n  \n\n\n\n\n\nsave_model(best, model_name='best-model')\n\nTransformation Pipeline and Model Succesfully Saved\n\n\n(Pipeline(memory=None,\n          steps=[('dtypes',\n                  DataTypes_Auto_infer(categorical_features=[],\n                                       display_types=True, features_todrop=[],\n                                       id_columns=[], ml_usecase='regression',\n                                       numerical_features=[], target='specific',\n                                       time_features=[])),\n                 ('imputer',\n                  Simple_Imputer(categorical_strategy='not_available',\n                                 fill_value_categorical=None,\n                                 fill_value_numerical=None,\n                                 numeric_strateg...\n                                            learning_rate=0.05, loss='ls',\n                                            max_depth=8, max_features='sqrt',\n                                            max_leaf_nodes=None,\n                                            min_impurity_decrease=0.001,\n                                            min_impurity_split=None,\n                                            min_samples_leaf=3,\n                                            min_samples_split=10,\n                                            min_weight_fraction_leaf=0.0,\n                                            n_estimators=260,\n                                            n_iter_no_change=None,\n                                            presort='deprecated',\n                                            random_state=153, subsample=1.0,\n                                            tol=0.0001, validation_fraction=0.1,\n                                            verbose=0, warm_start=False)]],\n          verbose=False),\n 'best-model.pkl')\n\n\n\nloaded_bestmodel = load_model('best-model')\nprint(loaded_bestmodel)\n\nTransformation Pipeline and Model Successfully Loaded\nPipeline(memory=None,\n         steps=[('dtypes',\n                 DataTypes_Auto_infer(categorical_features=[],\n                                      display_types=True, features_todrop=[],\n                                      id_columns=[], ml_usecase='regression',\n                                      numerical_features=[], target='specific',\n                                      time_features=[])),\n                ('imputer',\n                 Simple_Imputer(categorical_strategy='not_available',\n                                fill_value_categorical=None,\n                                fill_value_numerical=None,\n                                numeric_strateg...\n                                           learning_rate=0.05, loss='ls',\n                                           max_depth=8, max_features='sqrt',\n                                           max_leaf_nodes=None,\n                                           min_impurity_decrease=0.001,\n                                           min_impurity_split=None,\n                                           min_samples_leaf=3,\n                                           min_samples_split=10,\n                                           min_weight_fraction_leaf=0.0,\n                                           n_estimators=260,\n                                           n_iter_no_change=None,\n                                           presort='deprecated',\n                                           random_state=153, subsample=1.0,\n                                           tol=0.0001, validation_fraction=0.1,\n                                           verbose=0, warm_start=False)]],\n         verbose=False)\n\n\n\nfrom sklearn import set_config\nset_config(display='diagram')\nloaded_bestmodel[0]\n\nDataTypes_Auto_inferDataTypes_Auto_infer(categorical_features=[], display_types=True,\n                     features_todrop=[], id_columns=[], ml_usecase='regression',\n                     numerical_features=[], target='specific',\n                     time_features=[])\n\n\n\nfrom sklearn import set_config\nset_config(display='text')\n\n\nX_train = get_config('X_train')\nX_train.head()\n\n\n\n\n\n  \n    \n      \n      general\n      gdp\n      fdi\n      rnr\n      rr\n      i\n      fr\n      it\n      province_Anhui\n      province_Beijing\n      ...\n      year_2002\n      year_2003\n      year_2006\n      year_2007\n      reg_East China\n      reg_North China\n      reg_Northeast China\n      reg_Northwest China\n      reg_South Central China\n      reg_Southwest China\n    \n  \n  \n    \n      343\n      66100.0\n      2556.020020\n      8384.0\n      0.0\n      0.000000\n      0.000000\n      1807967.0\n      3388449.0\n      0.0\n      0.0\n      ...\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n    \n    \n      259\n      116000.0\n      12078.150391\n      601617.0\n      0.0\n      0.000000\n      0.000000\n      6166904.0\n      2940367.0\n      0.0\n      0.0\n      ...\n      0.0\n      1.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      190\n      655919.0\n      4056.760010\n      242000.0\n      0.0\n      0.410256\n      0.000000\n      2525301.0\n      3343228.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      1.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      319\n      50097.0\n      185.089996\n      467.0\n      0.0\n      0.000000\n      0.324324\n      70048.0\n      1333133.0\n      0.0\n      0.0\n      ...\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n    \n    \n      258\n      113000.0\n      10275.500000\n      473404.0\n      0.0\n      0.000000\n      0.000000\n      5145006.0\n      2455900.0\n      0.0\n      0.0\n      ...\n      1.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 47 columns\n\n\n\n\nget_config('seed')\n\n153\n\n\n\nfrom pycaret.regression import set_config\nset_config('seed', 999)\n\n\nget_config('seed')\n\n999\n\n\n\n!mlflow ui \n\n[2021-05-31 20:13:02 -0500] [56453] [INFO] Starting gunicorn 20.0.4\n[2021-05-31 20:13:02 -0500] [56453] [INFO] Listening at: http://127.0.0.1:5000 (56453)\n[2021-05-31 20:13:02 -0500] [56453] [INFO] Using worker: sync\n[2021-05-31 20:13:02 -0500] [56455] [INFO] Booting worker with pid: 56455\n^C\n[2021-05-31 20:13:35 -0500] [56453] [INFO] Handling signal: int\n[2021-05-31 20:13:35 -0500] [56455] [INFO] Worker exiting (pid: 56455)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  }
]